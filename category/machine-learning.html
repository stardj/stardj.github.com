<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<!--
Design by Free CSS Templates
http://www.freecsstemplates.org
Released for free under a Creative Commons Attribution 2.5 License

Name       : Brown Stone  
Description: A two-column, fixed-width design with dark color scheme.
Version    : 1.0
Released   : 20100928

-->
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta name="keywords" content="" />
<meta name="description" content="" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<title>Stardj is coding - Machine Learning</title>
<link href="/theme/css/style.css" rel="stylesheet" type="text/css" media="screen" />
<link href="/" type="application/atom+xml" rel="alternate" title="Stardj is coding ATOM Feed" />
</head>
<body>
<div id="wrapper">
	<div id="page">
		<div id="page-bgtop">
			<div id="page-bgbtm">
 
        
				<div id="content">
					<div class="post">
						<h2 class="title"><a href="/probability-and-other-preliminaries.html">Probability and Other Preliminaries</a></h2>
						<p class="meta"><span class="date">Le  </span><span class="posted">Par <a href="#">stardj</a></span><span>&nbsp; | Cat√©gorie : <a href="/category/machine-learning.html">Machine Learning</a></span></p>
					<p class="meta">Tags : <span><a href="/tag/learning-note.html">Learning note</a> / </span>
</p>
						<div style="clear: both;">&nbsp;</div>
						<div class="entry">
						 <h1>Probability and Other Preliminaries</h1>
<ul>
<li>probability distribution</li>
<li>rules of probability</li>
<li>review for linear algebra</li>
</ul>
<h3>Preview</h3>
<ul>
<li>topics this week mainly concerns a brief review for probability and linear algebra</li>
<li>lab class introduces use of Jupyter, Python and Pandas</li>
</ul>
<h3>Probability Distribution</h3>
<p>The <strong>probability distribution function</strong> of a random variable <span class="math">\(X\)</span> is
</p>
<div class="math">$$
  F(x) = P(X \leq x)
$$</div>
<p>
where the notation <span class="math">\(\{X \leq x\}\)</span> consists of all outcomes smaller than or equal to <span class="math">\(x\)</span>.</p>
<p>The derivative
</p>
<div class="math">$$
  p(x) = \frac{dF(x)}{dx}
$$</div>
<p>
is called the <strong>probability density function</strong> of <span class="math">\(X\)</span> .</p>
<p>Wikipedia:
<a href="https://en.wikipedia.org/wiki/Probability_distribution">Probability distribution</a> /
<a href="https://en.wikipedia.org/wiki/Probability_density_function">Probability density function</a></p>
<h3>Joint Distribution</h3>
<p>The <strong>joint distribution function</strong> of two random variables <span class="math">\(X\)</span> and <span class="math">\(Y\)</span> is the probability of the joint statistics <span class="math">\(\{X \leq x, Y \leq y\}\)</span>, ie,
</p>
<div class="math">$$
  F(x, y) = P(X \leq x, Y \leq y)
$$</div>
<p>The derivative
</p>
<div class="math">$$
  p(x, y) = \frac{\partial^2 F(x, y)}{\partial x \partial y}
$$</div>
<p>
is called the <strong>joint density function</strong> of <span class="math">\(X\)</span> and <span class="math">\(Y\)</span> .</p>
<ul>
<li><span class="math">\(X\)</span> and <span class="math">\(Y\)</span> are <strong>independent</strong> if and only if <span class="math">\(p(x,y) = p(x)p(y)\)</span></li>
</ul>
<p>Wikipedia: <a href="https://en.wikipedia.org/wiki/Joint_probability_distribution">Joint probability distribution</a></p>
<h3>Conditional Distribution</h3>
<p>Given two jointly distributed random variables <span class="math">\(X\)</span> and <span class="math">\(Y\)</span>, the <strong>conditional probability distribution</strong> of <span class="math">\(Y\)</span> given <span class="math">\(X\)</span> is the probability distribution of <span class="math">\(Y\)</span> when <span class="math">\(X\)</span> is known to be a particular value.</p>
<p>The <strong>conditional density function</strong> of <span class="math">\(y\)</span> given the occurrence of the value <span class="math">\(x\)</span> is
</p>
<div class="math">$$
  p(y|x) = \frac{p(x,y)}{p(x)}
$$</div>
<p>Wikipedia: <a href="https://en.wikipedia.org/wiki/Conditional_probability_distribution">Conditional probability distribution</a></p>
<h3>Gaussian (Normal) Distribution</h3>
<p>The probability density of the <strong>Gaussian distribution</strong> is
</p>
<div class="math">$$
  p(x\ |\ \mu,\sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left( -\frac{(x-\mu)^2}{2\sigma^2} \right)
$$</div>
<p>
where <span class="math">\(\mu\)</span> is the <strong>mean</strong> and <span class="math">\(\sigma^2\)</span> is the <strong>variance</strong> of the distribution.</p>
<ul>
<li>very common in natural and social sciences</li>
<li><span class="math">\(\sigma\)</span> is the <strong>standard deviation</strong></li>
</ul>
<p>Wikipedia: <a href="https://en.wikipedia.org/wiki/Normal_distribution">Normal distribution</a></p>
<h3>The Normal (Gaussian) Distribution</h3>
<div align="right">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Gaussian_distribution.svg/640px-Gaussian_distribution.svg.png", width=700>
</div>

<ul>
<li>about 68% of values drawn from a Gaussian distribution are within one standard deviation <span class="math">\(\sigma\)</span> from the mean <span class="math">\(\mu\)</span></li>
</ul>
<h3>Multivariate Gaussian (Normal) Distribution</h3>
<p>The probability density of the <span class="math">\(k\)</span>-dimensional <strong>Gaussian distribution</strong> is
</p>
<div class="math">$$
  p(\mathbf{x}\ |\ \boldsymbol{\mu},\boldsymbol{\Sigma}) = \frac{1}{\sqrt{2\pi^k |\boldsymbol{\Sigma}|}} \exp\left( -\frac{1}{2} (\mathbf{x}-\boldsymbol{\mu})^\top \boldsymbol{\Sigma}^{-1} (\mathbf{x}-\boldsymbol{\mu}) \right)
$$</div>
<p>
where <span class="math">\(\boldsymbol{\mu}\)</span> is the <span class="math">\(k\times 1\)</span> <strong>mean vector</strong> and <span class="math">\(\boldsymbol{\Sigma}\)</span> is the <span class="math">\(k\times k\)</span> <strong>covariance matrix</strong>.</p>
<ul>
<li><span class="math">\(|\boldsymbol{\Sigma}|\)</span> and <span class="math">\(\boldsymbol{\Sigma}^{-1}\)</span> are the <strong>determinant</strong> and the <strong>inverse</strong> of the covariance</li>
<li>a symbol <span class="math">\(~^\top\)</span> indicates the <strong>transpose</strong></li>
</ul>
<p>Wikipedia: <a href="https://en.wikipedia.org/wiki/Multivariate_normal_distribution">Multivariate normal distribution</a></p>
<h3>Notation</h3>
<p>Formally we should write out <span class="math">\(p(X=x,Y=y)\)</span> .</p>
<p>In practice we often use <span class="math">\(p(x,y)\)</span> .</p>
<ul>
<li>this looks very much like we might write a multivariate function, eg, <span class="math">\(f(x,y) = \frac{x}{y}\)</span></li>
<li>for a multivariate function though, <span class="math">\(f(x,y)\neq f(y,x)\)</span></li>
<li>however <span class="math">\(p(x,y) = p(y,x)\)</span> because <span class="math">\(p(X=x,Y=y) = p(Y=y,X=x)\)</span></li>
</ul>
<p>We now quickly review the <strong>rules of probability</strong>.</p>
<h3>Normalisation</h3>
<p>All distributions are normalised.</p>
<ul>
<li>this is clear from the fact that <span class="math">\(\sum_{x\in {\cal X}} n_{x} = N\)</span>, which gives
<div class="math">$$
  \sum_{x\in {\cal X}} p(x) = \lim_{N\rightarrow\infty} \frac{\sum_{x\in {\cal X}} n_x}{N} = \lim_{N\rightarrow\infty} \frac{N}{N} = 1
$$</div>
</li>
</ul>
<p>A similar result can be derived for the marginal and conditional distributions.</p>
<h3>Product Rule and Sum Rule</h3>
<p>The product rule of probability:
</p>
<div class="math">$$
  \underbrace{p(x,y)}_{\text{joint probability}} = \underbrace{p(y|x)}_{\text{conditional probability}}\cdot\ p(x)
$$</div>
<p>The sum rule of probability:
</p>
<div class="math">$$
  \underbrace{p(y)}_{\text{marginal probability}} = \sum_{x\in {\cal X}} p(x,y) = \sum_{x\in {\cal X}} p(y|x)p(x)
$$</div>
<p>Wikipedia:
<a href="https://en.wikipedia.org/wiki/Product_rule">Product rule</a> /
<a href="https://en.wikipedia.org/wiki/Probability_axioms">Probability axioms</a></p>
<h3>Bayes' Theorem</h3>
<p>Bayes' theorem immediately follows the product rule:
</p>
<div class="math">$$
  p(x|y) = \frac{p(x,y)}{p(y)} = \frac{p(y|x)p(x)}{\displaystyle \sum_{x\in {\cal X}} p(y|x)p(x)}
$$</div>
<p>Wikipedia: <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes' theorem</a></p>
<p>(<strong>Example</strong>)
There are two barrels in front of you.
Barrel One(B1) contains 20 apples and 4 oranges.
Barrel Two(B2) contains 4 apples and 8 oranges.
You choose a barrel randomly and select a fruit.
It is an <strong>apple</strong>.
What is the probability that the barrel was Barrel One?</p>
<p>(<strong>Solution</strong>) we are given that:
</p>
<div class="math">$$
\begin{align*}
  p(\text{apple}\ |\ \text{B}_1) = &amp; \frac{20}{24} &amp; \qquad p(\text{B}_1) = 0.5 \\
  p(\text{apple}\ |\ \text{B}_2) = &amp; \frac{4}{12} &amp; \qquad p(\text{B}_2) = 0.5
\end{align*}
$$</div>
<p>
Use the sum rule to calculate
</p>
<div class="math">$$
  p(\text{apple}) = p(\text{apple}\ |\ \text{B}_1)p(\text{B}_1) + p(\text{apple}\ |\ \text{B}_2)P(\text{B}_2) = \frac{20}{24}\times 0.5 + \frac{4}{12}\times 0.5 = \frac{7}{12}
$$</div>
<p>
and Bayes' theorem tells us that:
</p>
<div class="math">$$
  p(\text{B}_1\ |\ \text{apple}) = \frac{p(\text{apple}\ |\ \text{B}_1)P(\text{B}_1)}{P(\text{apple})} = \frac{\frac{20}{24}\times 0.5}{\frac{7}{12}} = \frac{5}{7}
$$</div>
<h3>Expected Value</h3>
<p>The <strong>expected value</strong> (or mean, average) of a random variable <span class="math">\(X\)</span> is
</p>
<div class="math">$$
  \mathbb{E}[X] = \int_{-\infty}^{\infty} xp(x) dx
$$</div>
<ul>
<li>discrete type is <span class="math">\(\mathbb{E}[X] = \sum_{x\in {\cal X}} x p(x)\)</span> for all possible events <span class="math">\({\cal X}\)</span></li>
</ul>
<p>The expected value of a function <span class="math">\(f(x)\)</span> is
</p>
<div class="math">$$
  \mathbb{E}[f(x)] = \int_{-\infty}^{\infty} f(x) p(x) dx
$$</div>
<p>Wikipedia: <a href="https://en.wikipedia.org/wiki/Expected_value">Expected value</a></p>
<h3>Variance</h3>
<p>The <strong>variance</strong> is the expected value of <span class="math">\(f(x) = (x - \mathbb{E}[X])^2\)</span>, ie,
</p>
<div class="math">$$
  \mathbb{V}ar[X] = \mathbb{E}[(X - \mathbb{E}[X])^2] = \int_{-\infty}^{\infty} (x - \mathbb{E}[X])^2 p(x) dx
$$</div>
<ul>
<li>discrete type is <span class="math">\(\mathbb{V}ar[X] = \sum_{x\in {\cal X}} (x - \mathbb{E}[X])^2 p(x)\)</span></li>
</ul>
<p>(note)
$
  \mathbb{V}ar[X]
  = \mathbb{E}[(X - \mathbb{E}[X])^2]
  = \mathbb{E}[X^2 - 2X\mathbb{E}(X) + \mathbb{E}[X]^2]
  = \mathbb{E}[X^2] - 2\mathbb{E}(X)\mathbb{E}(X) + \mathbb{E}[X]^2
  = \mathbb{E}[X^2] - \mathbb{E}[X]^2
$</p>
<p>Wikipedia: <a href="https://en.wikipedia.org/wiki/Variance">Variance</a></p>
<h3>Derivatives with Vectors</h3>
<p>We have scalars <span class="math">\(x\)</span>, <span class="math">\(y\)</span>, and <span class="math">\(n\)</span>- and <span class="math">\(m\)</span>-dimensional vectors <span class="math">\(\mathbf{x}\)</span>, <span class="math">\(\mathbf{y}\)</span>, where
</p>
<div class="math">$$
  \mathbf{x} = \left( \begin{array}{c} x_1 \\ \vdots \\ x_n \end{array} \right)
  \qquad
  \mathbf{y} = \left( \begin{array}{c} y_1 \\ \vdots \\ y_m \end{array} \right)
$$</div>
<p>
Derivatives with vectors using the <strong>denominator-layout</strong> notation:
</p>
<div class="math">$$
  \frac{\partial \mathbf{y}}{\partial x} = \left( \frac{\partial y_1}{\partial x} \cdots \frac{\partial y_m}{\partial x} \right)
  \qquad
  \frac{\partial y}{\partial \mathbf{x}} = \left( \begin{array}{c} \frac{\partial y}{\partial x_1} \\ \vdots \\ \frac{\partial y}{\partial x_n} \end{array} \right)
  \qquad
  \frac{\partial \mathbf{y}}{\partial \mathbf{x}} = \left( \begin{array}{ccc} \frac{\partial y_1}{\partial x_1} &amp; \cdots &amp; \frac{\partial y_m}{\partial x_1} \\ \vdots &amp; &amp; \vdots \\ \frac{\partial y_1}{\partial x_n} &amp; \cdots &amp; \frac{\partial y_m}{\partial x_n} \end{array} \right)
$$</div>
<h3>Some Scalar-by-Vector Identities</h3>
<p>For vectors <span class="math">\(\mathbf{a}\)</span>, <span class="math">\(\mathbf{w}\)</span> and a square matrix <span class="math">\(\mathbf{A}\)</span> :
</p>
<div class="math">$$
\begin{align*}
  \frac{\partial \mathbf{a}^\top \mathbf{w}}{\partial \mathbf{w}} = &amp; \mathbf{a} \\
  \frac{\partial \mathbf{w}^\top \mathbf{A} \mathbf{w}}{\partial \mathbf{w}} = &amp; (\mathbf{A} + \mathbf{A}^\top)\mathbf{w}
\end{align*}
$$</div>
<p>
Wikipedia: <a href="https://en.wikipedia.org/wiki/Matrix_calculus">Matrix calculus</a></p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>	
						</div>
					</div>
					<div style="clear: both;">&nbsp;</div>
				</div>
				<div id="sidebar">
					<div id="logo">
						<h1><a href="">Stardj is coding</a></h1>
					</div>
					<div id="menu">
						<ul>
							<li ><a href="">Home</a></li>
							<li ><a href="/archives.html">Archives</a></li>
						</ul>
					</div>
					<ul>
						<li>
							<h2>Cat√©gories</h2>
							<ul>
								 <li ><a href="/category/java.html">JAVA</a></li>
								 <li class="active"><a href="/category/machine-learning.html">Machine Learning</a></li>
								 <li ><a href="/category/uncategorized.html">Uncategorized</a></li>
								 <li ><a href="/category/ya-si.html">ÈõÖÊÄù</a></li>
							</ul>
						</li>
						<li>
							<h2>Blogroll</h2>
							<ul>
                                                            <li><a href="http://getpelican.com/">Pelican</a></li>
                                                            <li><a href="http://python.org/">Python.org</a></li>
                                                            <li><a href="http://jinja.pocoo.org/">Jinja2</a></li>
                                                            <li><a href="#">You can modify those links in your config file</a></li>
							</ul>
						</li>
                                                <li>
                                                        <h2>Social</h2>
                                                        <ul>
                                                            <li><a href="/" rel="alternate">Flux Atom</a></li>
                                                            <li><a href="#">You can add links in your config file</a></li>
                                                            <li><a href="#">Another social link</a></li>
                                                        </ul>
                                                </li><!-- /.social -->
						<li>
						        <h2>Tags</h2>
						        <ul>
                                                                <li><a href="/tag/learning-note.html">Learning note</a></li>
                                                                <li><a href="/tag/bei-wang-lu.html">Â§áÂøòÂΩï</a></li>
                                                                <li><a href="/tag/github-pages.html">Github-Pages</a></li>
                                                                <li><a href="/tag/blogs.html">Blogs</a></li>
                                                                <li><a href="/tag/pelican.html">Pelican</a></li>
                                                                <li><a href="/tag/markdown.html">Markdown</a></li>
						        </ul>
						</li>
						
						
					</ul>
				</div>
				<!-- end #sidebar -->
				<div style="clear: both;">&nbsp;</div>
			</div>
		</div>
	</div>
	<!-- end #page -->

<div id="footer">
	<p>Copyright (c) 2008 Sitename.com. All rights reserved. Design by <a href="http://www.freecsstemplates.org/">CSS Templates</a>.</p>
	<p>Proudly powered by <a href="http://alexis.notmyidea.org/pelican/">pelican</a>, which takes great advantages of <a href="http://python.org">python</a>.
</p>
</div>
<!-- end #footer -->
</body>
</html>