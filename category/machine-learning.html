<!DOCTYPE html>
<html lang="en">
<head>
        <title>Stardj is coding - Machine Learning</title>
        <meta charset="utf-8" />
        <link rel="stylesheet" href="/theme/css/main.css" type="text/css" />
   

        <!--[if IE]>
                <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

        <!--[if lte IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="/css/ie.css"/>
                <script src="/js/IE8.js" type="text/javascript"></script><![endif]-->

        <!--[if lt IE 7]>
                <link rel="stylesheet" type="text/css" media="all" href="/css/ie6.css"/><![endif]-->

</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="">Stardj is coding </a></h1>
                <nav><ul>
                    <li ><a href="/category/algorithm.html">Algorithm</a></li>
                    <li ><a href="/category/ielts.html">IELTS</a></li>
                    <li class="active"><a href="/category/machine-learning.html">Machine Learning</a></li>
                    <li ><a href="/category/uncategorized.html">Uncategorized</a></li>
                </ul></nav>
        </header><!-- /#banner -->
        
        

            <aside id="featured" class="body">
                <article>
                    <h1 class="entry-title"><a href="/probability-and-other-preliminaries.html">Probability and Other Preliminaries</a></h1> 
<footer class="post-info">
        <abbr class="published" title="2017-10-01T15:35:00+08:00">
                Sun 01 October 2017
        </abbr>

        <address class="vcard author">
                By <a class="url fn" href="/author/stardj.html">stardj</a>
        </address>
<p>In <a href="/category/machine-learning.html">Machine Learning</a>. </p>
<p>tags: <a href="/tag/learning-note.html">Learning note</a></p></footer><!-- /.post-info --><h1>Probability and Other Preliminaries</h1>
<ul>
<li>probability distribution</li>
<li>rules of probability</li>
<li>review for linear algebra</li>
</ul>
<h3>Preview</h3>
<ul>
<li>topics this week mainly concerns a brief review for probability and linear algebra</li>
<li>lab class introduces use of Jupyter, Python and Pandas</li>
</ul>
<h3>Probability Distribution</h3>
<p>The <strong>probability distribution function</strong> of a random variable <span class="math">\(X\)</span> is
</p>
<div class="math">$$
  F(x) = P(X \leq x)
$$</div>
<p>
where the notation <span class="math">\(\{X \leq x\}\)</span> consists of all outcomes smaller than or equal to <span class="math">\(x\)</span>.</p>
<p>The derivative
</p>
<div class="math">$$
  p(x) = \frac{dF(x)}{dx}
$$</div>
<p>
is called the <strong>probability density function</strong> of <span class="math">\(X\)</span> .</p>
<p>Wikipedia:
<a href="https://en.wikipedia.org/wiki/Probability_distribution">Probability distribution</a> /
<a href="https://en.wikipedia.org/wiki/Probability_density_function">Probability density function</a></p>
<h3>Joint Distribution</h3>
<p>The <strong>joint distribution function</strong> of two random variables <span class="math">\(X\)</span> and <span class="math">\(Y\)</span> is the probability of the joint statistics <span class="math">\(\{X \leq x, Y \leq y\}\)</span>, ie,
</p>
<div class="math">$$
  F(x, y) = P(X \leq x, Y \leq y)
$$</div>
<p>The derivative
</p>
<div class="math">$$
  p(x, y) = \frac{\partial^2 F(x, y)}{\partial x \partial y}
$$</div>
<p>
is called the <strong>joint density function</strong> of <span class="math">\(X\)</span> and <span class="math">\(Y\)</span> .</p>
<ul>
<li><span class="math">\(X\)</span> and <span class="math">\(Y\)</span> are <strong>independent</strong> if and only if <span class="math">\(p(x,y) = p(x)p(y)\)</span></li>
</ul>
<p>Wikipedia: <a href="https://en.wikipedia.org/wiki/Joint_probability_distribution">Joint probability distribution</a></p>
<h3>Conditional Distribution</h3>
<p>Given two jointly distributed random variables <span class="math">\(X\)</span> and <span class="math">\(Y\)</span>, the <strong>conditional probability distribution</strong> of <span class="math">\(Y\)</span> given <span class="math">\(X\)</span> is the probability distribution of <span class="math">\(Y\)</span> when <span class="math">\(X\)</span> is known to be a particular value.</p>
<p>The <strong>conditional density function</strong> of <span class="math">\(y\)</span> given the occurrence of the value <span class="math">\(x\)</span> is
</p>
<div class="math">$$
  p(y|x) = \frac{p(x,y)}{p(x)}
$$</div>
<p>Wikipedia: <a href="https://en.wikipedia.org/wiki/Conditional_probability_distribution">Conditional probability distribution</a></p>
<h3>Gaussian (Normal) Distribution</h3>
<p>The probability density of the <strong>Gaussian distribution</strong> is
</p>
<div class="math">$$
  p(x\ |\ \mu,\sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left( -\frac{(x-\mu)^2}{2\sigma^2} \right)
$$</div>
<p>
where <span class="math">\(\mu\)</span> is the <strong>mean</strong> and <span class="math">\(\sigma^2\)</span> is the <strong>variance</strong> of the distribution.</p>
<ul>
<li>very common in natural and social sciences</li>
<li><span class="math">\(\sigma\)</span> is the <strong>standard deviation</strong></li>
</ul>
<p>Wikipedia: <a href="https://en.wikipedia.org/wiki/Normal_distribution">Normal distribution</a></p>
<h3>The Normal (Gaussian) Distribution</h3>
<div align="right">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Gaussian_distribution.svg/640px-Gaussian_distribution.svg.png", width=700>
</div>

<ul>
<li>about 68% of values drawn from a Gaussian distribution are within one standard deviation <span class="math">\(\sigma\)</span> from the mean <span class="math">\(\mu\)</span></li>
</ul>
<h3>Multivariate Gaussian (Normal) Distribution</h3>
<p>The probability density of the <span class="math">\(k\)</span>-dimensional <strong>Gaussian distribution</strong> is
</p>
<div class="math">$$
  p(\mathbf{x}\ |\ \boldsymbol{\mu},\boldsymbol{\Sigma}) = \frac{1}{\sqrt{2\pi^k |\boldsymbol{\Sigma}|}} \exp\left( -\frac{1}{2} (\mathbf{x}-\boldsymbol{\mu})^\top \boldsymbol{\Sigma}^{-1} (\mathbf{x}-\boldsymbol{\mu}) \right)
$$</div>
<p>
where <span class="math">\(\boldsymbol{\mu}\)</span> is the <span class="math">\(k\times 1\)</span> <strong>mean vector</strong> and <span class="math">\(\boldsymbol{\Sigma}\)</span> is the <span class="math">\(k\times k\)</span> <strong>covariance matrix</strong>.</p>
<ul>
<li><span class="math">\(|\boldsymbol{\Sigma}|\)</span> and <span class="math">\(\boldsymbol{\Sigma}^{-1}\)</span> are the <strong>determinant</strong> and the <strong>inverse</strong> of the covariance</li>
<li>a symbol <span class="math">\(~^\top\)</span> indicates the <strong>transpose</strong></li>
</ul>
<p>Wikipedia: <a href="https://en.wikipedia.org/wiki/Multivariate_normal_distribution">Multivariate normal distribution</a></p>
<h3>Notation</h3>
<p>Formally we should write out <span class="math">\(p(X=x,Y=y)\)</span> .</p>
<p>In practice we often use <span class="math">\(p(x,y)\)</span> .</p>
<ul>
<li>this looks very much like we might write a multivariate function, eg, <span class="math">\(f(x,y) = \frac{x}{y}\)</span></li>
<li>for a multivariate function though, <span class="math">\(f(x,y)\neq f(y,x)\)</span></li>
<li>however <span class="math">\(p(x,y) = p(y,x)\)</span> because <span class="math">\(p(X=x,Y=y) = p(Y=y,X=x)\)</span></li>
</ul>
<p>We now quickly review the <strong>rules of probability</strong>.</p>
<h3>Normalisation</h3>
<p>All distributions are normalised.</p>
<ul>
<li>this is clear from the fact that <span class="math">\(\sum_{x\in {\cal X}} n_{x} = N\)</span>, which gives
<div class="math">$$
  \sum_{x\in {\cal X}} p(x) = \lim_{N\rightarrow\infty} \frac{\sum_{x\in {\cal X}} n_x}{N} = \lim_{N\rightarrow\infty} \frac{N}{N} = 1
$$</div>
</li>
</ul>
<p>A similar result can be derived for the marginal and conditional distributions.</p>
<h3>Product Rule and Sum Rule</h3>
<p>The product rule of probability:
</p>
<div class="math">$$
  \underbrace{p(x,y)}_{\text{joint probability}} = \underbrace{p(y|x)}_{\text{conditional probability}}\cdot\ p(x)
$$</div>
<p>The sum rule of probability:
</p>
<div class="math">$$
  \underbrace{p(y)}_{\text{marginal probability}} = \sum_{x\in {\cal X}} p(x,y) = \sum_{x\in {\cal X}} p(y|x)p(x)
$$</div>
<p>Wikipedia:
<a href="https://en.wikipedia.org/wiki/Product_rule">Product rule</a> /
<a href="https://en.wikipedia.org/wiki/Probability_axioms">Probability axioms</a></p>
<h3>Bayes' Theorem</h3>
<p>Bayes' theorem immediately follows the product rule:
</p>
<div class="math">$$
  p(x|y) = \frac{p(x,y)}{p(y)} = \frac{p(y|x)p(x)}{\displaystyle \sum_{x\in {\cal X}} p(y|x)p(x)}
$$</div>
<p>Wikipedia: <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes' theorem</a></p>
<p>(<strong>Example</strong>)
There are two barrels in front of you.
Barrel One(B1) contains 20 apples and 4 oranges.
Barrel Two(B2) contains 4 apples and 8 oranges.
You choose a barrel randomly and select a fruit.
It is an <strong>apple</strong>.
What is the probability that the barrel was Barrel One?</p>
<p>(<strong>Solution</strong>) we are given that:
</p>
<div class="math">$$
\begin{align*}
  p(\text{apple}\ |\ \text{B}_1) = &amp; \frac{20}{24} &amp; \qquad p(\text{B}_1) = 0.5 \\
  p(\text{apple}\ |\ \text{B}_2) = &amp; \frac{4}{12} &amp; \qquad p(\text{B}_2) = 0.5
\end{align*}
$$</div>
<p>
Use the sum rule to calculate
</p>
<div class="math">$$
  p(\text{apple}) = p(\text{apple}\ |\ \text{B}_1)p(\text{B}_1) + p(\text{apple}\ |\ \text{B}_2)P(\text{B}_2) = \frac{20}{24}\times 0.5 + \frac{4}{12}\times 0.5 = \frac{7}{12}
$$</div>
<p>
and Bayes' theorem tells us that:
</p>
<div class="math">$$
  p(\text{B}_1\ |\ \text{apple}) = \frac{p(\text{apple}\ |\ \text{B}_1)P(\text{B}_1)}{P(\text{apple})} = \frac{\frac{20}{24}\times 0.5}{\frac{7}{12}} = \frac{5}{7}
$$</div>
<h3>Expected Value</h3>
<p>The <strong>expected value</strong> (or mean, average) of a random variable <span class="math">\(X\)</span> is
</p>
<div class="math">$$
  \mathbb{E}[X] = \int_{-\infty}^{\infty} xp(x) dx
$$</div>
<ul>
<li>discrete type is <span class="math">\(\mathbb{E}[X] = \sum_{x\in {\cal X}} x p(x)\)</span> for all possible events <span class="math">\({\cal X}\)</span></li>
</ul>
<p>The expected value of a function <span class="math">\(f(x)\)</span> is
</p>
<div class="math">$$
  \mathbb{E}[f(x)] = \int_{-\infty}^{\infty} f(x) p(x) dx
$$</div>
<p>Wikipedia: <a href="https://en.wikipedia.org/wiki/Expected_value">Expected value</a></p>
<h3>Variance</h3>
<p>The <strong>variance</strong> is the expected value of <span class="math">\(f(x) = (x - \mathbb{E}[X])^2\)</span>, ie,
</p>
<div class="math">$$
  \mathbb{V}ar[X] = \mathbb{E}[(X - \mathbb{E}[X])^2] = \int_{-\infty}^{\infty} (x - \mathbb{E}[X])^2 p(x) dx
$$</div>
<ul>
<li>discrete type is <span class="math">\(\mathbb{V}ar[X] = \sum_{x\in {\cal X}} (x - \mathbb{E}[X])^2 p(x)\)</span></li>
</ul>
<p>(note)
$
  \mathbb{V}ar[X]
  = \mathbb{E}[(X - \mathbb{E}[X])^2]
  = \mathbb{E}[X^2 - 2X\mathbb{E}(X) + \mathbb{E}[X]^2]
  = \mathbb{E}[X^2] - 2\mathbb{E}(X)\mathbb{E}(X) + \mathbb{E}[X]^2
  = \mathbb{E}[X^2] - \mathbb{E}[X]^2
$</p>
<p>Wikipedia: <a href="https://en.wikipedia.org/wiki/Variance">Variance</a></p>
<h3>Derivatives with Vectors</h3>
<p>We have scalars <span class="math">\(x\)</span>, <span class="math">\(y\)</span>, and <span class="math">\(n\)</span>- and <span class="math">\(m\)</span>-dimensional vectors <span class="math">\(\mathbf{x}\)</span>, <span class="math">\(\mathbf{y}\)</span>, where
</p>
<div class="math">$$
  \mathbf{x} = \left( \begin{array}{c} x_1 \\ \vdots \\ x_n \end{array} \right)
  \qquad
  \mathbf{y} = \left( \begin{array}{c} y_1 \\ \vdots \\ y_m \end{array} \right)
$$</div>
<p>
Derivatives with vectors using the <strong>denominator-layout</strong> notation:
</p>
<div class="math">$$
  \frac{\partial \mathbf{y}}{\partial x} = \left( \frac{\partial y_1}{\partial x} \cdots \frac{\partial y_m}{\partial x} \right)
  \qquad
  \frac{\partial y}{\partial \mathbf{x}} = \left( \begin{array}{c} \frac{\partial y}{\partial x_1} \\ \vdots \\ \frac{\partial y}{\partial x_n} \end{array} \right)
  \qquad
  \frac{\partial \mathbf{y}}{\partial \mathbf{x}} = \left( \begin{array}{ccc} \frac{\partial y_1}{\partial x_1} &amp; \cdots &amp; \frac{\partial y_m}{\partial x_1} \\ \vdots &amp; &amp; \vdots \\ \frac{\partial y_1}{\partial x_n} &amp; \cdots &amp; \frac{\partial y_m}{\partial x_n} \end{array} \right)
$$</div>
<h3>Some Scalar-by-Vector Identities</h3>
<p>For vectors <span class="math">\(\mathbf{a}\)</span>, <span class="math">\(\mathbf{w}\)</span> and a square matrix <span class="math">\(\mathbf{A}\)</span> :
</p>
<div class="math">$$
\begin{align*}
  \frac{\partial \mathbf{a}^\top \mathbf{w}}{\partial \mathbf{w}} = &amp; \mathbf{a} \\
  \frac{\partial \mathbf{w}^\top \mathbf{A} \mathbf{w}}{\partial \mathbf{w}} = &amp; (\mathbf{A} + \mathbf{A}^\top)\mathbf{w}
\end{align*}
$$</div>
<p>
Wikipedia: <a href="https://en.wikipedia.org/wiki/Matrix_calculus">Matrix calculus</a></p>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>                </article>
<p class="paginator">
    Page 1 / 1
</p>
            </aside><!-- /#featured -->
            </ol><!-- /#posts-list -->
            </section><!-- /#content -->
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>blogroll</h2>
                        <ul>
                            <li><a href="http://getpelican.com/">Pelican</a></li>
                            <li><a href="http://python.org/">Python.org</a></li>
                            <li><a href="http://jinja.pocoo.org/">Jinja2</a></li>
                            <li><a href="#">You can modify those links in your config file</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>
                            
                            <li><a href="#">You can add links in your config file</a></li>
                            <li><a href="#">Another social link</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">

        </footer><!-- /#contentinfo -->

</body>
</html>